{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 도구변수 추정\n",
    "- 작성자: 고려대학교 경제학과 한치록 교수, 데이터사이언스팀 이창훈 과장\n",
    "\n",
    "설명변수에 내생적(회귀식 오차항과 상관)인 변수가 포함되어 있을 때 OLS 추정량은 편향되고 이 편향은 표본크기가 아무리 커도 해소되지 않는다. 오히려 표본크기가 크면 클수록 잘못된 모수를 점점 더 분명하게 추정한다. 계량경제학에서는 이 경우 도구변수 추정법이 널리 사용된다. 도구변수 추정법이 작동하기 위해서는 최소한 내생적 설명변수 개수만큼의 추가 도구변수가 필요하다. 이 추가 도구변수들($Z$)은 외생적이어야 하고 내생적 설명변수들($X$)과 충분히 강하게 상관되어야 한다. 추가 도구변수의 선택은 연구자의 몫이다.\n",
    "\n",
    "## Two-Stage Least Squares (2SLS)\n",
    "\n",
    "도구변수 추정법 중 가장 널리 사용되는 것이 2단계 최소제곱법(2SLS)이다. 이 방법은 우선 내생적 설명변수들($X_2$)을 모든 외생변수들(외생적 설명변수들 $X_1$과 추가 도구변수들 $Z_2$)에 대하여 OLS 회귀한 다음 fitted values ($\\hat{X}_2$)를 구하고(1단계 회귀), 그 다음 종속변수($y$)를 외생적 설명변수들($X_1$)과 이들 fitted values $\\hat{X}_2$에 대하여 OLS 회귀하는 방법이다. 단, 둘째 단계 회귀에서 자동으로 도출되는 표준오차는 잘못이므로 제대로 된 표준오차를 따로 구하여야 한다.\n",
    "\n",
    "2SLS는 [linearmodels][lm] 패키지의 `IV2SLS` 모듈에 구현되어 있다([statsmodels][sm] 패키지에도 기초적인 구현이 시도되어 있으나 0.15 버전에서는 사용할 수 있을 정도는 아니다). 그런데 [linearmodels][lm] 패키지의 수식 인터페이스는 절편을 자동으로 포함하지 않으므로 매우 불편하다. 이에 [linearmodels][lm] 패키지의 수식 인터페이스 부분을 `bok_da` 라이브러리에서 monkey patch하였다. monkey patch란 동적으로 특정 패키지에 코드를 덧붙이거나 기존 소스코드를 교체해서 원래의 동작을 사용자가 원하는 동작으로 변경하는 기법이다. `import bok_da`를 하면 패치가 적용된다. 원래 `IV2SLS`는 `robust` standard error 계산이 디폴트로 되어 있으나, monkey patch 시에 `unadjust`가 디폴트가 되도록 수정하였다.\n",
    "\n",
    "2SLS는 다음 예제와 같이 하면 된다. 외생적 설명변수가 `exp76`과 `smsa76`이고 내생적 설명변수는 `ed76`, 추가 도구변수는 `momed`와 `daded`인 경우이다. 이는 formular에서 `[ed76 ~ momed+daded]`로 표현한다. 이 표현은 `ed76`을 내생변수로 보고, `momed`와 `daded`를 그에 대한 도구변수로 쓰겠다는 것을 의미한다. 아래에서 `import bok_da` 부분은 매우 중요하다. 이걸 해야 monkey patch가 이루어지기 때문이다.\n",
    "\n",
    "[sm]: https://www.statsmodels.org/\n",
    "[lm]: https://bashtage.github.io/linearmodels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:                lwage76   R-squared:                      0.1705\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.1696\n",
      "No. Observations:                3010   F-statistic:                    359.02\n",
      "Date:                Thu, May 22 2025   P-value (F-stat)                0.0000\n",
      "Time:                        15:11:18   Distribution:                  chi2(3)\n",
      "Cov. Estimator:            unadjusted                                         \n",
      "                                                                              \n",
      "                               Parameter Estimates                               \n",
      "=================================================================================\n",
      "               Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         3.8318     0.1813     21.133     0.0000      3.4764      4.1871\n",
      "exp76             0.0604     0.0049     12.453     0.0000      0.0509      0.0699\n",
      "smsa76[T.yes]     0.1559     0.0177     8.8197     0.0000      0.1213      0.1905\n",
      "ed76              0.1345     0.0109     12.331     0.0000      0.1131      0.1559\n",
      "=================================================================================\n",
      "\n",
      "Endogenous: ed76\n",
      "Instruments: momed, daded\n",
      "Unadjusted Covariance (Homoskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "import bok_da\n",
    "import pandas as pd\n",
    "from linearmodels import IV2SLS\n",
    "\n",
    "df = pd.read_csv('../data/Schooling.csv')\n",
    "fm = 'lwage76 ~ [ed76 ~ momed+daded] + exp76 + smsa76'\n",
    "mod = IV2SLS.from_formula(fm, data=df)\n",
    "tsls = mod.fit()\n",
    "print(tsls.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2SLS 관련 검정\n",
    "\n",
    "### First-stage tests\n",
    "\n",
    "도구변수가 내생적 설명변수와 충분히 상관되었는지를 보는 제1단계 검정(first-stage tests)은 다음과 같이 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    First Stage Estimation Results    \n",
      "======================================\n",
      "                                  ed76\n",
      "--------------------------------------\n",
      "R-squared                       0.5000\n",
      "Partial R-squared               0.1130\n",
      "Shea's R-squared                0.1130\n",
      "Partial F-statistic             191.64\n",
      "P-value (Partial F-stat)      1.11e-16\n",
      "Partial F-stat Distn         F(2,3005)\n",
      "========================== ===========\n",
      "Intercept                       13.412\n",
      "                              (70.982)\n",
      "exp76                          -0.3558\n",
      "                             (-39.940)\n",
      "smsa76[T.yes]                   0.4220\n",
      "                              (5.4425)\n",
      "momed                           0.1539\n",
      "                              (11.044)\n",
      "daded                           0.1111\n",
      "                              (8.6693)\n",
      "--------------------------------------\n",
      "\n",
      "T-stats reported in parentheses\n",
      "T-stats use same covariance type as original model\n"
     ]
    }
   ],
   "source": [
    "print(tsls.first_stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위에서 R-squared는 내생적 설명변수(`ed76`)을 외생적 설명변수들(`exp76`과 `smsa76`)과 추가 도구변수들(`momed`와 `daded`)에 대하여 회귀할 때의 R-squared이다. 이 값이 크다는 것은 내생적 설명변수에 대한 도구변수들의 설명력이 높다는 것이다. 한 가지 문제는 우리에게 필요한 것은 추가 도구변수emf의 설명력이 높아야 한다는 것인데, 추가 설명변수들의 기여는 낮으면서 외생적 설명변수들의 기여가 높아 R제곱이 클 수도 있다는 것이다. 그러므로 다른 지표들도 살펴보아야 한다.\n",
    "\n",
    "* R-squared와 달리 Partial R-squared는 외생적 설명변수들을 통제한 상태에서 추가 도구변수들의 설명력을 의미한다. 이 수치는 내생적 설명변수(`ed76`)를 외생적 설명변수들에 대하여 회귀하여 잔차($\\tilde{x}_2$라 하자)를 구하고, 추가적 도구변수들(`momed`와 `daded`) 각각을 외생적 설명변수들에 대하여 회귀하여 잔차($\\tilde{z}_{2a}$와 $\\tilde{z}_{2b}$라 하자)를 구한 후, $\\tilde{x}_2$를 $\\tilde{z}_{2a}$와 $\\tilde{z}_{2b}$에 대하여 (절편 없이) 회귀할 때의 R제곱을 의미한다.\n",
    "\n",
    "* Shea (1997)의 R-squared (partial R-squared)는 내생적 설명변수가 복수 개일 때까지 고려된 통계이다. 만약 내생적 설명변수가 1개이면 Shea의 partial R-squared는 partial R-squared와 동일하다.\n",
    "\n",
    "* Partial F-statistic은 first-stage F 검정통계량으로서, 내생적 설명변수를 모든 외생변수들(외생적 설명변수와 추가 도구변수)에 대하여 OLS 회귀할 때 추가 도구변수들의 계수가 0이라는 귀무가설에 해당하는 검정통계량이다. 보통 이 값이 10보다 크면 도구변수가 강하다고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endogeneity test\n",
    "\n",
    "내생적 설명변수가 1개일 때 제1단계 회귀로부터 얻은 잔차($\\hat{v}_2$)를 회귀식에 포함시켜서 OLS 추정을 하고 $\\hat{v}_2$의 계수가 0인지 검정함으로써 내생성 여부를 검정할 수 있다(귀무가설은 `ed76`이 외생적라는 것). 예를 들어 다음과 같이 해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                lwage76   R-squared:                      0.2209\n",
      "Model:                            OLS   Adj. R-squared:                 0.2198\n",
      "No. Observations:                3010   F-statistic:                     213.0\n",
      "Covariance Type:            nonrobust   Prob (F-statistic):             0.0000\n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        3.83175    0.17587      21.79      0.000     3.48692     4.17658\n",
      "smsa76[T.yes]    0.15590    0.01715       9.09      0.000     0.12228     0.18952\n",
      "ed76             0.13450    0.01058      12.71      0.000     0.11375     0.15524\n",
      "exp76            0.06041    0.00471      12.84      0.000     0.05119     0.06964\n",
      "vhat            -0.05263    0.01123      -4.69      0.000    -0.07466    -0.03061\n",
      "=================================================================================\n",
      "\n",
      "Notes:\n",
      "1. Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.api import OLS\n",
    "\n",
    "reg1 = OLS.from_formula('ed76 ~ exp76+smsa76+momed+daded', data=df).fit()\n",
    "df['vhat'] = reg1.resid\n",
    "reg2 = OLS.from_formula('lwage76 ~ ed76+exp76+smsa76 + vhat', data=df).fit()\n",
    "print(reg2.summary(slim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "회귀 결과 마지막 줄에 `vhat`의 `t`값은 -4.69이고 p값이 0.000이므로 `ed76`이 외생적이라는 귀무가설은 기각된다. `linearmodels`에서 이는 fitting 후에 `.wooldridge_regression` 프로퍼티로써 구할 수 있다. 단, t검정이 아니라 카이제곱 검정을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wooldridge's regression test of exogeneity\n",
       "H0: Endogenous variables are exogenous\n",
       "Statistic: 21.9909\n",
       "P-value: 0.0000\n",
       "Distributed: chi2(1)\n",
       "WaldTestStatistic, id: 0x1cd8771ad50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsls.wooldridge_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과에서 Statistic 값은 위의 t통계량을 제곱한 것과 (거의) 같고 p값도 (거의) 같다. 위 결과에 의하면 `ed76` 변수는 내생적이라는 결론을 얻는다.\n",
    "\n",
    "### Overidentification test\n",
    "\n",
    "추가적 도구변수들이 모두 외생적인지 검정해 보자. 이 검정은 추가 도구변수의 개수가 내생적 설명변수의 개수와 동일하면 실행할 수 없고, 추가 도구변수의 개수가 내생적 설명변수의 개수보다 더 크면(즉, overidentify되면) 실행할 수 있는 검정이므로 \"overidentification test\"라 한다. `linearmodels`에서는 다음 명령으로 검정을 수행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wooldridge's score test of overidentification\n",
       "H0: Model is not overidentified.\n",
       "Statistic: 3.1853\n",
       "P-value: 0.0743\n",
       "Distributed: chi2(1)\n",
       "WaldTestStatistic, id: 0x1cd8771b200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsls.wooldridge_overid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limited Information Maximum Likelihood\n",
    "\n",
    "`LIML(Limited Information Maximum Likelihood)`은 단일 방정식만 보고 최대우도 원리로 내생변수를 보정하는 IV 추정법으로, 특히 도구변수가 약할 때(weak instruments) 2SLS보다 효율성과 편향 보정 측면에서 유리하다. 도구변수가 내생변수를 충분히 설명하지 못해 1단계 회귀에서 설명력이 약한 상황에서 LIML이 편향을 일부 조정해 줄 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-LIML Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:                lwage76   R-squared:                      0.1696\n",
      "Estimator:                    IV-LIML   Adj. R-squared:                 0.1688\n",
      "No. Observations:                3010   F-statistic:                    358.36\n",
      "Date:                Thu, May 22 2025   P-value (F-stat)                0.0000\n",
      "Time:                        15:20:41   Distribution:                  chi2(3)\n",
      "Cov. Estimator:            unadjusted                                         \n",
      "                                                                              \n",
      "                               Parameter Estimates                               \n",
      "=================================================================================\n",
      "               Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         3.8243     0.1822     20.992     0.0000      3.4672      4.1813\n",
      "exp76             0.0606     0.0049     12.439     0.0000      0.0511      0.0701\n",
      "smsa76[T.yes]     0.1556     0.0177     8.7947     0.0000      0.1209      0.1903\n",
      "ed76              0.1350     0.0110     12.313     0.0000      0.1135      0.1564\n",
      "=================================================================================\n",
      "\n",
      "Endogenous: ed76\n",
      "Instruments: momed, daded\n",
      "Unadjusted Covariance (Homoskedastic)\n",
      "Debiased: False\n",
      "Kappa: 1.001\n"
     ]
    }
   ],
   "source": [
    "import bok_da\n",
    "import pandas as pd\n",
    "from linearmodels import IVLIML\n",
    "\n",
    "df = pd.read_csv('../data/Schooling.csv')\n",
    "fm = 'lwage76 ~ [ed76 ~ momed+daded] + exp76 + smsa76'\n",
    "mod = IVLIML.from_formula(fm, data=df)\n",
    "liml = mod.fit()\n",
    "print(liml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bok_da_test_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
